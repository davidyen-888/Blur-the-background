<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>File Input Detextion</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
</head>

<body>
    <div>
        Choose a file: <input type="file" id="file-input" onchange="loadfile(this)" />
    </div>
    <canvas id="cvs"></canvas>
    <Script>
        const ctx = document.querySelector('#cvs').getContext('2d');  // get canvas context

        // Load the blazeface model in advance. Prevent the browser from loading the model every time the page is loaded.
        let model = null;
        async function init() {
            model = await blazeface.load();
        }
        init();

        function loadfile(input) {
            const file = input.files[0];    // get the user selected file
            const img = new Image();  // create a new image object from file object
            img.src = URL.createObjectURL(file);  // create a random url from file object
            img.addEventListener("load", () => {
                ctx.canvas.width = img.width;
                ctx.canvas.height = img.height;
                // ctx.drawImage(img, 0, 0);
                detect(img);
            });
        }
        async function detect(img) {


            // Pass in an image or video to the model. The model returns an array of
            // bounding boxes, probabilities, and landmarks, one for each detected face.

            const returnTensors = false; // Pass in `true` to get tensors back, rather than values.
            const predictions = await model.estimateFaces(img, returnTensors);

            if (predictions.length > 0) {   // If there are faces detected.
                /*
                `predictions` is an array of objects describing each detected face, for example:
            
                [
                  {
                    topLeft: [232.28, 145.26],
                    bottomRight: [449.75, 308.36],
                    probability: [0.998],
                    landmarks: [
                      [295.13, 177.64], // right eye
                      [382.32, 175.56], // left eye
                      [341.18, 205.03], // nose
                      [345.12, 250.61], // mouth
                      [252.76, 211.37], // right ear
                      [431.20, 204.93] // left ear
                    ]
                  }
                ]
                */
                // Get the top-left and bottom-right coordinates of the faces by using for loop.
                for (let i = 0; i < predictions.length; i++) {
                    const rightEye = predictions[i].landmarks[0];
                    const leftEye = predictions[i].landmarks[1];
                    const start = predictions[i].topLeft;
                    const end = predictions[i].bottomRight;
                    const size = [end[0] - start[0], end[1] - start[1]];

                    // Render a rectangle over each detected face.
                    // ctx.fillRect(start[0], start[1], size[0], size[1]);

                    // Render a clear image in face.
                    const faceArea = new Path2D();    // create a new Path2D object
                    // Calculate the center of the face as the midpoint between the rightEye and leftEye coordinates.
                    faceArea.ellipse(
                        (leftEye[0] + rightEye[0]) / 2, 
                        (leftEye[1] + rightEye[1]) / 2,
                        size[0] / 2, size[1] * 0.8,
                        0, 0, 2 * Math.PI
                        );

                    // Only draw the image at the coordinates defined above a.k.a. the face part.
                    ctx.save();
                    ctx.clip(faceArea); // Clip the canvas to the area of the face
                    ctx.drawImage(img, 0, 0);
                    ctx.restore();

                }
            }
            // Add blur background to the image.
            ctx.save();
            ctx.filter = 'blur(10px)';
            ctx.globalCompositeOperation = 'destination-atop';    // If the image was drawn, preserve the pre-existing image, draw only on the place never drawn before.
            ctx.drawImage(img, 0, 0);
            ctx.restore()
        }
    </Script>
</body>

</html>